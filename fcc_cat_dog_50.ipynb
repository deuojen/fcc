{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deuojen/fcc/blob/main/fcc_cat_dog_50.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "la_Oz6oLlub6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "792e8062-d62b-4ebb-a677-3b5222f05a1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "  # This command only in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jaF8r6aOl48C"
      },
      "outputs": [],
      "source": [
        "# Get project files\n",
        "!wget https://cdn.freecodecamp.org/project-data/cats-and-dogs/cats_and_dogs.zip\n",
        "\n",
        "!unzip cats_and_dogs.zip\n",
        "\n",
        "PATH = 'cats_and_dogs'\n",
        "\n",
        "train_dir = os.path.join(PATH, 'train')\n",
        "validation_dir = os.path.join(PATH, 'validation')\n",
        "test_dir = os.path.join(PATH, 'test')\n",
        "\n",
        "# Get number of files in each directory. The train and validation directories\n",
        "# each have the subdirecories \"dogs\" and \"cats\".\n",
        "total_train = sum([len(files) for r, d, files in os.walk(train_dir)])\n",
        "total_val = sum([len(files) for r, d, files in os.walk(validation_dir)])\n",
        "total_test = len(os.listdir(test_dir))\n",
        "\n",
        "# Variables for pre-processing and training.\n",
        "batch_size = 128\n",
        "epochs = 15\n",
        "IMG_HEIGHT = 150\n",
        "IMG_WIDTH = 150"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "EOJFeEfumns6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "226703c4-2e0f-445f-e05c-55576dde0b09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2000 images belonging to 2 classes.\n",
            "Found 1000 images belonging to 2 classes.\n",
            "Found 50 images belonging to 1 classes.\n"
          ]
        }
      ],
      "source": [
        "# 3\n",
        "# EXAMPLE: see \"Example of using .flow_from_directory(directory):\" in\n",
        "#https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator\n",
        "# EXAMPLE 2: see \"classifier_from_little_data_script_1.py\" in\n",
        "#https://gist.github.com/fchollet/0830affa1f7f19fd47b06d4cf89ed44d?utm_source=www.tensorflow.org&utm_medium=referral\n",
        "\n",
        "# 3.1. Create image generators for each of the three image data sets\n",
        "#(train, validation, test). Use ImageDataGenerator to read / decode\n",
        "#the images and convert them into floating point tensors. Use the\n",
        "#rescale argument (and no other arguments for now) to rescale the\n",
        "#tensors from values between 0 and 255 to values between 0 and 1.\n",
        "\n",
        "train_image_generator = ImageDataGenerator(rescale=1./255)\n",
        "validation_image_generator = ImageDataGenerator(rescale=1./255)\n",
        "test_image_generator = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# 3.2. For the *_data_gen variables, use the flow_from_directory method.\n",
        "#Pass in the batch size, directory, target size ((IMG_HEIGHT, IMG_WIDTH)),\n",
        "#class mode, and anything else required. test_data_gen will be the trickiest\n",
        "#one. For test_data_gen, make sure to pass in shuffle=False to the\n",
        "#flow_from_directory method. This will make sure the final predictions stay\n",
        "#is in the order that our test expects. For test_data_gen it will also be\n",
        "#helpful to observe the directory structure.\n",
        "\n",
        "#flow_from_directory(\n",
        "#    directory,\n",
        "#    target_size=(256, 256),\n",
        "#    color_mode='rgb',\n",
        "#    classes=None,\n",
        "#    class_mode='categorical',\n",
        "#    batch_size=32,\n",
        "#    shuffle=True,\n",
        "#    seed=None,\n",
        "#    save_to_dir=None,\n",
        "#    save_prefix='',\n",
        "#    save_format='png',\n",
        "#    follow_links=False,\n",
        "#    subset=None,\n",
        "#    interpolation='nearest',\n",
        "#    keep_aspect_ratio=False\n",
        "#)\n",
        "\n",
        "train_data_gen = train_image_generator.flow_from_directory(\n",
        "    train_dir, target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=batch_size, class_mode='binary', shuffle=True\n",
        "    #classes=['cats', 'dogs']\n",
        ")\n",
        "val_data_gen = validation_image_generator.flow_from_directory(\n",
        "    validation_dir, target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=batch_size, class_mode='binary', shuffle=True\n",
        "    #classes=['cats', 'dogs']\n",
        ")\n",
        "test_data_gen = test_image_generator.flow_from_directory(directory=PATH,\n",
        "                                                         classes=['test'],\n",
        "                                                         target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                         batch_size=batch_size,\n",
        "                                                         shuffle=False,)\n",
        "\n",
        "# After you run the code, the output should look like this:\n",
        "#Found 2000 images belonging to 2 classes.\n",
        "#Found 1000 images belonging to 2 classes.\n",
        "#Found 50 images belonging to 1 class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TP0WA8j1mt7Q"
      },
      "outputs": [],
      "source": [
        "# 4\n",
        "\n",
        "# The plotImages function will be used a few times to plot images. It takes an\n",
        "#array of images and a probabilities list, although the probabilities list is\n",
        "#optional. This code is given to you. If you created the train_data_gen variable\n",
        "#correctly, then running this cell will plot five random training images\n",
        "\n",
        "def plotImages(images_arr, probabilities = False):\n",
        "    fig, axes = plt.subplots(len(images_arr), 1, figsize=(5,len(images_arr) * 3))\n",
        "    if probabilities is False:\n",
        "      for img, ax in zip( images_arr, axes):\n",
        "          ax.imshow(img)\n",
        "          ax.axis('off')\n",
        "    else:\n",
        "      for img, probability, ax in zip( images_arr, probabilities, axes):\n",
        "          ax.imshow(img)\n",
        "          ax.axis('off')\n",
        "          if probability > 0.5:\n",
        "              ax.set_title(\"%.2f\" % (probability*100) + \"% dog\")\n",
        "          else:\n",
        "              ax.set_title(\"%.2f\" % ((1-probability)*100) + \"% cat\")\n",
        "    plt.show()\n",
        "\n",
        "sample_training_images, _ = next(train_data_gen)\n",
        "plotImages(sample_training_images[:5])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "-32RRLY_3voj"
      },
      "outputs": [],
      "source": [
        "# 5\n",
        "\n",
        "# Recreate the train_image_generator using ImageDataGenerator.\n",
        "\n",
        "# Since there are a small number of training examples, there is a risk of\n",
        "#overfitting (not having enought training data). One way to fix this problem\n",
        "#is by creating more training data from existing training examples by using\n",
        "#random transformations.\n",
        "\n",
        "# Add 4-6 random transformations as arguments to ImageDataGenerator. Make sure\n",
        "#to rescale the same as before.\n",
        "\n",
        "train_image_generator = ImageDataGenerator(rescale=1./255,\n",
        "                                           rotation_range=45,\n",
        "                                           vertical_flip=True,\n",
        "                                           horizontal_flip=True)\n",
        "# ImageDataGenerator(\n",
        "#     rescale=1/255,\n",
        "#     width_shift_range=0.01,\n",
        "#     height_shift_range=0.01,\n",
        "#     rotation_range=30,\n",
        "#     zoom_range=0.2,\n",
        "#     #shear_range=20.0,\n",
        "#     brightness_range=(0.40,0.80),\n",
        "#     channel_shift_range=30.0,\n",
        "#     horizontal_flip=True\n",
        "#     #vertical_flip=True,\n",
        "# )\n",
        "\n",
        "# Arguments examples explained:\n",
        "#https://towardsdatascience.com/exploring-image-data-augmentation-with-keras-and-tensorflow-a8162d89b844"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pkwq2LFvqabS"
      },
      "outputs": [],
      "source": [
        "# 6\n",
        "\n",
        "# You don't have to do anything for this cell. train_data_gen is created just\n",
        "#like before but with the new train_image_generator. Then, a single image is\n",
        "#plotted five different times using different variations.\n",
        "\n",
        "train_data_gen = train_image_generator.flow_from_directory(batch_size=batch_size,\n",
        "                                                     directory=train_dir,\n",
        "                                                     target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                     class_mode='binary',\n",
        "                                                     shuffle=True)\n",
        "# PERSONAL NOTE: train_data_gen receives 16 batches of batch_size=128 images\n",
        "#(previously defined), each image with a shape of 150x150 (height x width) and\n",
        "#3 channels.\n",
        "\n",
        "# train_data_gen[0][0][0] means first image of the training images\n",
        "augmented_images = [train_data_gen[0][0][0] for i in range(5)]\n",
        "plotImages(augmented_images)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print(train_data_gen[0][0].shape)\n",
        "# print(train_data_gen.n)\n",
        "# print(train_data_gen.labels)\n",
        "\n",
        "# create augmented images\n",
        "#augmented_train_images = [ train_data_gen[0][0][i] for i in range(train_data_gen.n) for _ in range(5) ]\n",
        "# create augmented images's labels\n",
        "#_, train_labels = next(train_data_gen)\n",
        "#augmented_train_labels = [ train_labels[i] for i in range(train_data_gen.n) for _ in range(5) ]\n",
        "\n",
        "#print(len(augmented_train_images))\n",
        "#print(len(augmented_train_labels))"
      ],
      "metadata": {
        "id": "aGfrnMgaiuP_"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "k8aZkwMam4UY"
      },
      "outputs": [],
      "source": [
        "# 7\n",
        "\n",
        "# 7.1. In this cell, create a model for the neural network that outputs class\n",
        "#probabilities. It should use the Keras Sequential model. It will probably\n",
        "#involve a stack of Conv2D and MaxPooling2D layers...\n",
        "\n",
        "# Create Keras Sequential Model\n",
        "model = Sequential()\n",
        "\n",
        "# Build Convolutional Base (a stack of Conv2D and MaxPooling2D layers)\n",
        "model.add( Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)) )\n",
        "model.add( MaxPooling2D(pool_size=(2, 2)) )\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "# PERSONAL NOTE: These two type of layers (convolutional and MaxPooling) will\n",
        "#extract the features from the image.\n",
        "#Going to process 32 filters of size 3x3 over the input shape\n",
        "#of the data, which is (height, width, channels) = (150, 150, 3).\n",
        "#Then, will perform the max pooling operation using 2x2 samples and a stride\n",
        "#of 2 (if strides=None (default), it will default to pool_size).\n",
        "\n",
        "#model.summary()\n",
        "# PERSONAL OBSERVATION: After looking at the summary it's worth noting that\n",
        "#the depth (frequency of filters) of our image increases but the spacial\n",
        "#dimensions (height and width) reduce (shrinks) drastically."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 7.2. ... and then [involve] a fully connected layer on top that is activated by a ReLU\n",
        "#activation function.\n",
        "\n",
        "model.add( Flatten() )\n",
        "model.add(Dense(1, activation='relu'))\n",
        "# model.add( Dense(64, activation='relu') )\n",
        "# model.add( Dropout(0.5) )\n",
        "# model.add( Dense(1, activation='sigmoid') )\n",
        "# PERSONAL NOTE: Then these extracted features (after finishing the convolutional\n",
        "#base) are flattened and fed to densely connected layers that determine the class\n",
        "#of an image based on the presence of features.\n",
        "# The Flatten layer changes the shape of the data as to feed it to\n",
        "#the 64-node dense layer, followed by the final output layer of 2\n",
        "#neurons (one for each class: 'cats' and 'dogs').\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "7te_csfvi0qt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7.3. Compile the model passing the arguments to set the optimizer and loss. Also\n",
        "#pass in metrics=['accuracy'] to view training and validation accuracy for each\n",
        "#training epoch.\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# model.compile(optimizer='rmsprop',\n",
        "#               loss='binary_crossentropy',\n",
        "#               metrics=['accuracy'])\n",
        "\n",
        "# More on built-in loss functions:\n",
        "#https://www.tensorflow.org/api_docs/python/tf/keras/losses"
      ],
      "metadata": {
        "id": "CVQwOVkte71V"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1niQDz5x6K7y"
      },
      "outputs": [],
      "source": [
        "# 8\n",
        "\n",
        "# Use the fit method on your model to train the network. Make sure to pass in\n",
        "#arguments for x, steps_per_epoch, epochs, validation_data, and validation_steps.\n",
        "\n",
        "history = model.fit(train_data_gen, validation_data=val_data_gen, epochs=epochs)\n",
        "\n",
        "# model.fit(\n",
        "#     x=train_data_gen,\n",
        "#     steps_per_epoch=total_train // batch_size,\n",
        "#     epochs=epochs,\n",
        "#     validation_data=val_data_gen,\n",
        "#     validation_steps=total_val // batch_size,\n",
        "#     verbose=1\n",
        "# )\n",
        "\n",
        "# More on fit method:\n",
        "#https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit\n",
        "\n",
        "#verbose -> 'auto', 0, 1, or 2. Verbosity mode. 0 = silent, 1 = progress bar,\n",
        "#2 = one line per epoch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5xS51mB56OAC"
      },
      "outputs": [],
      "source": [
        "# 9\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vYrSifOit2aK"
      },
      "outputs": [],
      "source": [
        "# 10\n",
        "\n",
        "predictions = model.predict(test_data_gen)\n",
        "plotImages(test_data_gen[0][0], probabilities=predictions)\n",
        "print(predictions)\n",
        "\n",
        "# Now it is time to use your model to predict whether a brand new image is a cat\n",
        "#or a dog.\n",
        "\n",
        "# In this cell, get the probability that each test image (from test_data_gen) is\n",
        "#a dog or a cat. probabilities should be a list of integers.\n",
        "\n",
        "# train_images, train_labels = next(train_data_gen)\n",
        "# val_images, val_labels = next(val_data_gen)\n",
        "# test_images, _ = next(test_data_gen)\n",
        "# plotImages(test_images[:2])\n",
        "#print(train_labels)\n",
        "\n",
        "# probabilities = model.predict(test_data_gen[0][0])\n",
        "# probabilities = np.reshape( np.round(probabilities), newshape=(50) ).tolist()\n",
        "# print(probabilities)\n",
        "#plotImages(test_images, probabilities)\n",
        "\n",
        "#augmented_images = [train_data_gen[0][0][0] for i in range(5)]\n",
        "#plotImages(augmented_images)\n",
        "\n",
        "# Call the plotImages function and pass in the test images and the probabilities\n",
        "#corresponding to each test image.\n",
        "# plotImages(test_data_gen[0][0], probabilities)\n",
        "\n",
        "# After you run the cell, you should see all 50 test images with a label showing\n",
        "#the percentage of \"sure\" that the image is a cat or a dog. The accuracy will\n",
        "#correspond to the accuracy shown in the graph above (after running the previous\n",
        "#cell). More training images could lead to a higher accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "IOywxmQqXIxM"
      },
      "outputs": [],
      "source": [
        "#print(test_data_gen.n)\n",
        "#print(test_data_gen.labels)\n",
        "#print(test_images.shape)\n",
        "#print(probabilities)\n",
        "#print(probabilities.shape)\n",
        "#print(test_images[0])\n",
        "#print(test_data_gen[0][0].shape)\n",
        "#dir(test_data_gen)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4IH86Ux_u7TZ"
      },
      "outputs": [],
      "source": [
        "# 11\n",
        "answers =  [1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0,\n",
        "            1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0,\n",
        "            1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1,\n",
        "            1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1,\n",
        "            0, 0, 0, 0, 0, 0]\n",
        "\n",
        "correct = 0\n",
        "\n",
        "for probability, answer in zip(probabilities, answers):\n",
        "  if round(probability) == answer:\n",
        "    correct +=1\n",
        "\n",
        "percentage_identified = (correct / len(answers)) * 100\n",
        "\n",
        "passed_challenge = percentage_identified >= 63\n",
        "\n",
        "print(f\"Your model correctly identified {round(percentage_identified, 2)}% of the images of cats and dogs.\")\n",
        "\n",
        "if passed_challenge:\n",
        "  print(\"You passed the challenge!\")\n",
        "else:\n",
        "  print(\"You haven't passed yet. Your model should identify at least 63% of the images. Keep trying. You will get it!\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "fcc_cat_dog.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}